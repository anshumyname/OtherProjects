{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Resume Scorer ( Information Retrieval Assignment )</h1>\n",
    "<h3>Name - Anshuman Srivastava</h3>\n",
    "<h3>Roll - BTECH/10408/18</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> <b>Problem Statement and Dataset</b> <br> A Hackerearth  competition named <a href=\"https://www.hackerearth.com/challenges/competitive/hackerearth-machine-learning-challenge-resume-shortlisting/?utm_source=challenges-modern&utm_campaign=participated-challenges&utm_medium=right-panel\">\"A Perfect Fit - ML Challenge\"</a> was held in August 2021. Broadly the problem solution was to retrieve the valuable information from a resume and score it according to a given Job Describtion. I have used the a set of 150 resumes to train the model which was available in a competition </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Approach</b></h2>\n",
    "<ul>\n",
    "<li> <h3> <b>Step 1 - Convert to Txt</b> - Since the resume are in pdf formats first we need to convert them into readable formats (txt here). <br> For this purpose I have used \"pdf2miner\" python library and stored all resumes in txt format.</h3></li>\n",
    "<br>\n",
    "<li><h3><b>Step 2 - Cleaning & WordBreak</b> - Now we have resume text and before moving further we must preprocess it removing all kinds of stopwords, URLs, whitespaces etc.. using \"NLTK\" library.After cleaning is done the whole text is split into words</h3></li>\n",
    "<br>\n",
    "<li><h3><b>Step 3 - Splitting Into Sections</b> - This is the main part where we divide words in 5 categories ( [\"personal\",\"projects\",\"experience\",\"skills\",\"education\"]) . We do a linear scan over all words and take find these 5 keywords in the resume and take correspoding lines after them. </h3></li>\n",
    "<br>\n",
    "<li><h3><b>Step 4 - Vectorization and Calculating Cosine</b> - For each section we transform each word to its \"Glove vector of 100 dimenstions\" and then accumulate their average over each dimension. Above 4 steps will be applied to JD also and then we will compare the cosing similarity of two vectors for each section </h3></li>\n",
    "<br>\n",
    "<li><h3><b>Step 5 - Score from Cosine Similarities </b> - Now we will have 5 cosine similaries according corresponding to a Job Description . Next step we will make a small Neural Network with 5 input layers 2 hidden layers and 1 output layers. We will train the network through the train data given. Hence obtaining a score of how much the resume is perfect fit for the corresponding Job Description</h3></li>\n",
    "\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h3>CODE</h3></b> \n",
    "<h5>Since Step 1 was very small I have started with Step2 here</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing Libraries\n",
    "'''\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Declaring Constants\n",
    "'''\n",
    "keywords = [\"personal\",\"projects\",\"experience\",\"skills\",\"education\"]\n",
    "stop_words = stopwords.words('english')\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_WORDS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cleaning Resume Text obtained after converting PDF to txt\n",
    "'''\n",
    "def cleanResume(resumeText):\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    resumeText = [x for x in resumeText.split() if x not in stop_words]     #Removing stopwords\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to divide the text into 5 sections as discussed\n",
    "'''\n",
    "def read_txt (path_to_folder, dir):\n",
    "    indexes = []\n",
    "    categories = {}\n",
    "    for w in keywords:\n",
    "        categories[w] = []\n",
    "    for filename in dir:\n",
    "        file = open(path_to_folder + filename,'r')\n",
    "        read = file.read()\n",
    "        read = read.lower()\n",
    "        file.close()\n",
    "\n",
    "        read = cleanResume(read)\n",
    "\n",
    "        hash = {}\n",
    "        hash[\"personal\"] =0\n",
    "        for word in keywords:\n",
    "            if word in read:\n",
    "                hash[word] = read.index(word)\n",
    "\n",
    "\n",
    "        items = sorted(hash.items(), key = lambda x: x[1])\n",
    "        for i in range(len(items)):\n",
    "            start = items[i][1]\n",
    "            end = None\n",
    "            if (i+1)==len(items):\n",
    "                end = len(read)\n",
    "            else:\n",
    "                end = items[i+1][1]\n",
    "\n",
    "            categories[items[i][0]].append(read[start:end])\n",
    "\n",
    "        for w in keywords:\n",
    "            if w not in hash.keys():\n",
    "                categories[w].append('None') \n",
    "\n",
    "        indexes.append(filename)\n",
    "    return  categories, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.listdir('./train_txt/')\n",
    "categories, indexes = read_txt('./train_txt/',dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "words_dict = ['None']\n",
    "for i in range(len(indexes)):\n",
    "    row = []\n",
    "    for w in keywords:\n",
    "        row.append(categories[w][i])\n",
    "        if categories[w][i] is not  None:\n",
    "            words_dict+=categories[w][i]\n",
    "\n",
    "    data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal</th>\n",
       "      <th>projects</th>\n",
       "      <th>experience</th>\n",
       "      <th>skills</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>candidate_000.txt</th>\n",
       "      <td>[personal, profile, actively, seeking, opportu...</td>\n",
       "      <td>[projects, music, genre, classification, face,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[skills, python, sql, mysql, tableau, power, b...</td>\n",
       "      <td>[education, b, tech, ece, vit, ap, university,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_001.txt</th>\n",
       "      <td>[brianna, williams, junior, developer, executi...</td>\n",
       "      <td>[projects, also, contribute, knowledge, logica...</td>\n",
       "      <td>[experience, curiosity, driven, data, scientis...</td>\n",
       "      <td>[skills, towards, consistent, growth, developm...</td>\n",
       "      <td>[education, teamwork, bsc, ca, mamco, universi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_002.txt</th>\n",
       "      <td>[mason, quadrado, associate, analyst, certifie...</td>\n",
       "      <td>None</td>\n",
       "      <td>[experience, analyzing, interpreting, data, go...</td>\n",
       "      <td>[skills, python, machine, learning, mysql, dat...</td>\n",
       "      <td>[education, b, tech, b, e, electronics, teleco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_003.txt</th>\n",
       "      <td>[associate, software, engineer]</td>\n",
       "      <td>[projects, koy, ok, 1e, im, ge, tena, wal, tur...</td>\n",
       "      <td>[experience, software, engineer, machine, lear...</td>\n",
       "      <td>[skills, ava, alo, avin, zt, od, al, ms, 1, da...</td>\n",
       "      <td>[education, b, tech, v, v, 2018, activities, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_006.txt</th>\n",
       "      <td>[jennifer, armstrong, computer, vision, enthus...</td>\n",
       "      <td>[projects, understanding, images, gan, based, ...</td>\n",
       "      <td>[experience, currently, professional, experience]</td>\n",
       "      <td>[skills, machine, learning, deep, learning, co...</td>\n",
       "      <td>[education, b, tech, computer, science, iit, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_144.txt</th>\n",
       "      <td>[benjamin, osta, fresher, developer, professio...</td>\n",
       "      <td>[projects, proficient]</td>\n",
       "      <td>None</td>\n",
       "      <td>[skills, software, engineer, software, develop...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_145.txt</th>\n",
       "      <td>[jerome, pelinsky, big, data, analyst, big, da...</td>\n",
       "      <td>None</td>\n",
       "      <td>[experience, handling, kinds, data, also, used...</td>\n",
       "      <td>[skills, big, data, hadoop, hive, python, mapr...</td>\n",
       "      <td>[education, b, tech, electronics, amity, schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_147.txt</th>\n",
       "      <td>[jaroslav, chechnik, executive, profile, work]</td>\n",
       "      <td>[projects, music, genre, classification, face,...</td>\n",
       "      <td>[experience, looking, job, opportunity, expert...</td>\n",
       "      <td>[skills, b, tech, ece, vit, ap, university, 20...</td>\n",
       "      <td>[education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_148.txt</th>\n",
       "      <td>[data, scientist]</td>\n",
       "      <td>[projects, acvaline, daal, lan, el, kx, 1e, mm...</td>\n",
       "      <td>[experience, building, deploying, end, end, an...</td>\n",
       "      <td>[skills, dy, esxoll, alot, dy, ha, wy, val, hv...</td>\n",
       "      <td>[education, b, tech, b, e, computers, rajiv, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_149.txt</th>\n",
       "      <td>[personal, profile, machine, learning, enginee...</td>\n",
       "      <td>[projects, wesbite, using, react, made, fully,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[skills, artificial, intelligence, deep, learn...</td>\n",
       "      <td>[education, b, tech, hit, kancheepuram, chenna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            personal  \\\n",
       "candidate_000.txt  [personal, profile, actively, seeking, opportu...   \n",
       "candidate_001.txt  [brianna, williams, junior, developer, executi...   \n",
       "candidate_002.txt  [mason, quadrado, associate, analyst, certifie...   \n",
       "candidate_003.txt                    [associate, software, engineer]   \n",
       "candidate_006.txt  [jennifer, armstrong, computer, vision, enthus...   \n",
       "...                                                              ...   \n",
       "candidate_144.txt  [benjamin, osta, fresher, developer, professio...   \n",
       "candidate_145.txt  [jerome, pelinsky, big, data, analyst, big, da...   \n",
       "candidate_147.txt     [jaroslav, chechnik, executive, profile, work]   \n",
       "candidate_148.txt                                  [data, scientist]   \n",
       "candidate_149.txt  [personal, profile, machine, learning, enginee...   \n",
       "\n",
       "                                                            projects  \\\n",
       "candidate_000.txt  [projects, music, genre, classification, face,...   \n",
       "candidate_001.txt  [projects, also, contribute, knowledge, logica...   \n",
       "candidate_002.txt                                               None   \n",
       "candidate_003.txt  [projects, koy, ok, 1e, im, ge, tena, wal, tur...   \n",
       "candidate_006.txt  [projects, understanding, images, gan, based, ...   \n",
       "...                                                              ...   \n",
       "candidate_144.txt                             [projects, proficient]   \n",
       "candidate_145.txt                                               None   \n",
       "candidate_147.txt  [projects, music, genre, classification, face,...   \n",
       "candidate_148.txt  [projects, acvaline, daal, lan, el, kx, 1e, mm...   \n",
       "candidate_149.txt  [projects, wesbite, using, react, made, fully,...   \n",
       "\n",
       "                                                          experience  \\\n",
       "candidate_000.txt                                               None   \n",
       "candidate_001.txt  [experience, curiosity, driven, data, scientis...   \n",
       "candidate_002.txt  [experience, analyzing, interpreting, data, go...   \n",
       "candidate_003.txt  [experience, software, engineer, machine, lear...   \n",
       "candidate_006.txt  [experience, currently, professional, experience]   \n",
       "...                                                              ...   \n",
       "candidate_144.txt                                               None   \n",
       "candidate_145.txt  [experience, handling, kinds, data, also, used...   \n",
       "candidate_147.txt  [experience, looking, job, opportunity, expert...   \n",
       "candidate_148.txt  [experience, building, deploying, end, end, an...   \n",
       "candidate_149.txt                                               None   \n",
       "\n",
       "                                                              skills  \\\n",
       "candidate_000.txt  [skills, python, sql, mysql, tableau, power, b...   \n",
       "candidate_001.txt  [skills, towards, consistent, growth, developm...   \n",
       "candidate_002.txt  [skills, python, machine, learning, mysql, dat...   \n",
       "candidate_003.txt  [skills, ava, alo, avin, zt, od, al, ms, 1, da...   \n",
       "candidate_006.txt  [skills, machine, learning, deep, learning, co...   \n",
       "...                                                              ...   \n",
       "candidate_144.txt  [skills, software, engineer, software, develop...   \n",
       "candidate_145.txt  [skills, big, data, hadoop, hive, python, mapr...   \n",
       "candidate_147.txt  [skills, b, tech, ece, vit, ap, university, 20...   \n",
       "candidate_148.txt  [skills, dy, esxoll, alot, dy, ha, wy, val, hv...   \n",
       "candidate_149.txt  [skills, artificial, intelligence, deep, learn...   \n",
       "\n",
       "                                                           education  \n",
       "candidate_000.txt  [education, b, tech, ece, vit, ap, university,...  \n",
       "candidate_001.txt  [education, teamwork, bsc, ca, mamco, universi...  \n",
       "candidate_002.txt  [education, b, tech, b, e, electronics, teleco...  \n",
       "candidate_003.txt  [education, b, tech, v, v, 2018, activities, a...  \n",
       "candidate_006.txt  [education, b, tech, computer, science, iit, g...  \n",
       "...                                                              ...  \n",
       "candidate_144.txt                                               None  \n",
       "candidate_145.txt  [education, b, tech, electronics, amity, schoo...  \n",
       "candidate_147.txt                                        [education]  \n",
       "candidate_148.txt  [education, b, tech, b, e, computers, rajiv, g...  \n",
       "candidate_149.txt  [education, b, tech, hit, kancheepuram, chenna...  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This is how our data looks after Step 2\n",
    "'''\n",
    "df = pd.DataFrame(data, index=indexes, columns=keywords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lets do the same for our target resume/JD which is assumed to have a score of 1.\n",
    "'''\n",
    "dir = ['Job description.txt']\n",
    "cat, _ = read_txt('./', dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next step is to transform the words to their glove vector\n",
    "'''\n",
    "embeddings_dict = {}\n",
    "embed_keys = []\n",
    "with open(\"glove.6B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        embed_keys.append(word)\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unk tokens 10\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Handling unknown tokens and taking the average over each dimension\n",
    "'''\n",
    "jd_vec = {}\n",
    "unks = 0\n",
    "for w in keywords:\n",
    "    vecs = []\n",
    "    for word in cat[w][0]:\n",
    "        if word in embed_keys:\n",
    "            vecs.append(embeddings_dict[word])\n",
    "        else:\n",
    "            unks+=1\n",
    "            vecs.append(embeddings_dict['<unk>'])\n",
    "    vecs = np.array(vecs)\n",
    "    avg = np.average(vecs, axis = 0)\n",
    "    jd_vec[w] = avg\n",
    "\n",
    "print(\"Total unk tokens\" , unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words extracted are  2319\n",
      "Total unk tokens 450\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Calculating cosing smilarity for each section of each candidate using JD\n",
    "'''\n",
    "sim_df = []\n",
    "unks=0\n",
    "all_words = []\n",
    "for i in range(len(indexes)):\n",
    "    row = []\n",
    "    for w in keywords:\n",
    "        vecs = []\n",
    "        for word in categories[w][i]:\n",
    "            all_words.append(word)\n",
    "            if word in embed_keys:\n",
    "                vecs.append(embeddings_dict[word])\n",
    "            else:\n",
    "                unks+=1\n",
    "                vecs.append(embeddings_dict['<unk>'])\n",
    "        vecs = np.array(vecs)\n",
    "        va = np.average(vecs, axis = 0)\n",
    "        cosine = None\n",
    "        if np.isnan(va).any():\n",
    "            cosine = 0\n",
    "        else:\n",
    "            vb = jd_vec[w]\n",
    "            cosine = dot(va,vb)/(norm(va)*norm(vb))\n",
    "        \n",
    "        row.append(cosine)\n",
    "    \n",
    "    sim_df.append(row)\n",
    "\n",
    "all_words = set(all_words)\n",
    "print(\"Total words extracted are \", len(all_words))\n",
    "print(\"Total unk tokens\" , unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal</th>\n",
       "      <th>projects</th>\n",
       "      <th>experience</th>\n",
       "      <th>skills</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>candidate_000.txt</th>\n",
       "      <td>0.888378</td>\n",
       "      <td>0.295928</td>\n",
       "      <td>0.415252</td>\n",
       "      <td>0.636419</td>\n",
       "      <td>0.856955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_001.txt</th>\n",
       "      <td>0.610979</td>\n",
       "      <td>0.234160</td>\n",
       "      <td>0.776972</td>\n",
       "      <td>0.762761</td>\n",
       "      <td>0.882273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_002.txt</th>\n",
       "      <td>0.668103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620666</td>\n",
       "      <td>0.924627</td>\n",
       "      <td>0.754305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_003.txt</th>\n",
       "      <td>0.694706</td>\n",
       "      <td>0.378404</td>\n",
       "      <td>0.694232</td>\n",
       "      <td>0.825477</td>\n",
       "      <td>0.770898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_006.txt</th>\n",
       "      <td>0.906714</td>\n",
       "      <td>0.300554</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.881404</td>\n",
       "      <td>0.773082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_144.txt</th>\n",
       "      <td>0.900714</td>\n",
       "      <td>0.164987</td>\n",
       "      <td>0.415252</td>\n",
       "      <td>0.853482</td>\n",
       "      <td>0.393262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_145.txt</th>\n",
       "      <td>0.738020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758193</td>\n",
       "      <td>0.920389</td>\n",
       "      <td>0.725882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_147.txt</th>\n",
       "      <td>0.576090</td>\n",
       "      <td>0.273347</td>\n",
       "      <td>0.758924</td>\n",
       "      <td>0.730275</td>\n",
       "      <td>0.708900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_148.txt</th>\n",
       "      <td>0.698836</td>\n",
       "      <td>0.395247</td>\n",
       "      <td>0.733054</td>\n",
       "      <td>0.694591</td>\n",
       "      <td>0.529111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_149.txt</th>\n",
       "      <td>0.872008</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>0.415252</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.740257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   personal  projects  experience    skills  education\n",
       "candidate_000.txt  0.888378  0.295928    0.415252  0.636419   0.856955\n",
       "candidate_001.txt  0.610979  0.234160    0.776972  0.762761   0.882273\n",
       "candidate_002.txt  0.668103  1.000000    0.620666  0.924627   0.754305\n",
       "candidate_003.txt  0.694706  0.378404    0.694232  0.825477   0.770898\n",
       "candidate_006.txt  0.906714  0.300554    0.769333  0.881404   0.773082\n",
       "...                     ...       ...         ...       ...        ...\n",
       "candidate_144.txt  0.900714  0.164987    0.415252  0.853482   0.393262\n",
       "candidate_145.txt  0.738020  1.000000    0.758193  0.920389   0.725882\n",
       "candidate_147.txt  0.576090  0.273347    0.758924  0.730275   0.708900\n",
       "candidate_148.txt  0.698836  0.395247    0.733054  0.694591   0.529111\n",
       "candidate_149.txt  0.872008  0.358750    0.415252  0.663939   0.740257\n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This is how our data looks after calculating 5 section similarity with the JD\n",
    "'''\n",
    "# Similartiy Table\n",
    "similariy = pd.DataFrame(sim_df, index=indexes, columns=keywords)\n",
    "similariy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "similariy.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array(similariy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CandidateID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>candidate_011</th>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_113</th>\n",
       "      <td>36.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_123</th>\n",
       "      <td>54.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_012</th>\n",
       "      <td>41.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_002</th>\n",
       "      <td>48.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Match Percentage\n",
       "CandidateID                    \n",
       "candidate_011             13.60\n",
       "candidate_113             36.63\n",
       "candidate_123             54.93\n",
       "candidate_012             41.46\n",
       "candidate_002             48.91"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv('./dataset/train.csv', index_col='CandidateID')\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ys = []\n",
    "for i in indexes:\n",
    "    ys.append(target.loc[i[:-4]]['Match Percentage']/100)\n",
    "ys = np.array(ys, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 5)\n",
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "xs = xs.astype(np.float32)\n",
    "ys = ys.astype(np.float32)\n",
    "print(xs.shape)\n",
    "print(ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now we have caluclated cosines and we will feed it to our neural network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense , Dropout, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Building and Training Model\n",
    "'''\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_shape =[5,]))\n",
    "    model.add(Dense(8))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics =['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 3s 146ms/step - loss: 0.8432 - mse: 0.8432 - val_loss: 0.7007 - val_mse: 0.7007\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5713 - mse: 0.5713 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4523 - mse: 0.4523 - val_loss: 0.5309 - val_mse: 0.5309\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3858 - mse: 0.3858 - val_loss: 0.4918 - val_mse: 0.4918\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3401 - mse: 0.3401 - val_loss: 0.4664 - val_mse: 0.4664\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3108 - mse: 0.3108 - val_loss: 0.4479 - val_mse: 0.4479\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2898 - mse: 0.2898 - val_loss: 0.4330 - val_mse: 0.4330\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2775 - mse: 0.2775 - val_loss: 0.4166 - val_mse: 0.4166\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2616 - mse: 0.2616 - val_loss: 0.4046 - val_mse: 0.4046\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2484 - mse: 0.2484 - val_loss: 0.3900 - val_mse: 0.3900\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2377 - mse: 0.2377 - val_loss: 0.3813 - val_mse: 0.3813\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.3512 - val_mse: 0.3512\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2079 - mse: 0.2079 - val_loss: 0.3393 - val_mse: 0.3393\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1986 - mse: 0.1986 - val_loss: 0.3259 - val_mse: 0.3259\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1910 - mse: 0.1910 - val_loss: 0.3135 - val_mse: 0.3135\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1802 - mse: 0.1802 - val_loss: 0.3005 - val_mse: 0.3005\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1718 - mse: 0.1718 - val_loss: 0.2883 - val_mse: 0.2883\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1633 - mse: 0.1633 - val_loss: 0.2768 - val_mse: 0.2768\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1559 - mse: 0.1559 - val_loss: 0.2642 - val_mse: 0.2642\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 0.2537 - val_mse: 0.2537\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1380 - mse: 0.1380 - val_loss: 0.2459 - val_mse: 0.2459\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1325 - mse: 0.1325 - val_loss: 0.2336 - val_mse: 0.2336\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1236 - mse: 0.1236 - val_loss: 0.2270 - val_mse: 0.2270\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 0.2177 - val_mse: 0.2177\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 0.2059 - val_mse: 0.2059\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.2057 - val_mse: 0.2057\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 0.1830 - val_mse: 0.1830\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.1747 - val_mse: 0.1747\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 0.1743 - val_mse: 0.1743\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.1567 - val_mse: 0.1567\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0770 - mse: 0.0770 - val_loss: 0.1488 - val_mse: 0.1488\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.1454 - val_mse: 0.1454\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.1247 - val_mse: 0.1247\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.1248 - val_mse: 0.1248\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.1185 - val_mse: 0.1185\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.1122 - val_mse: 0.1122\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.1035 - val_mse: 0.1035\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.1002 - val_mse: 0.1002\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.1014 - val_mse: 0.1014\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.1076 - val_mse: 0.1076\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0893 - val_mse: 0.0893\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0838 - val_mse: 0.0838\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0703 - val_mse: 0.0703\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0588 - val_mse: 0.0588\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0468 - val_mse: 0.0468\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=100,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Training Results</b></h3>\n",
    "<h3>Loss - 0.02 <br>\n",
    " MSE - 0.02 </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_mse'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "dir = os.listdir('./test_txt/')\n",
    "test_cat, test_index = read_txt('./test_txt/',dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Performing Tests and Calculating Score\n",
    "'''\n",
    "test_df = []\n",
    "for i in range(len(test_index)):\n",
    "    row = []\n",
    "    for w in keywords:\n",
    "        vecs = []\n",
    "        for word in test_cat[w][i]:\n",
    "            if word in embed_keys:\n",
    "                vecs.append(embeddings_dict[word])\n",
    "            else:\n",
    "                vecs.append(embeddings_dict['<unk>'])\n",
    "        vecs = np.array(vecs)\n",
    "        va = np.average(vecs, axis = 0)\n",
    "        cosine = None\n",
    "        if np.isnan(va).any():\n",
    "            cosine = 0\n",
    "        else:\n",
    "            vb = jd_vec[w]\n",
    "            cosine = dot(va,vb)/(norm(va)*norm(vb))\n",
    "        \n",
    "        row.append(cosine)\n",
    "    \n",
    "    test_df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 60 entries, candidate_004.txt to candidate_146.txt\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   personal    60 non-null     float64\n",
      " 1   projects    60 non-null     float32\n",
      " 2   experience  60 non-null     float32\n",
      " 3   skills      60 non-null     float32\n",
      " 4   education   60 non-null     float32\n",
      "dtypes: float32(4), float64(1)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_sim = pd.DataFrame(test_df, index=test_index, columns=keywords)\n",
    "test_sim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 5)\n"
     ]
    }
   ],
   "source": [
    "txs = np.array(test_sim)\n",
    "print(txs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(txs)\n",
    "ans = np.reshape(ans, (ans.shape[0],1))\n",
    "ans = ans*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(ans,test_index):\n",
    "    ans = np.reshape(ans, (ans.shape[0],1))\n",
    "    ans_index = np.array([x[:-4] for x in test_index])\n",
    "    ans_index = np.reshape(np.ravel(ans_index) , ans.shape)\n",
    "    ans = np.concatenate([ans_index,ans] , axis = 1)\n",
    "    ans_df = pd.DataFrame(ans, index=None, columns=['CandidateID','Match Percentage'])\n",
    "    print(\"Written new file\")\n",
    "    ans_df.to_csv('submission.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>RESULTS</h3>\n",
    "<img src=\"https://mega.nz/file/D2AFyKaZ#Hvq8xFQw8mINfQ6KYb8fvQFYjhUvdC-DLcIWCxD7fEk\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Trying other models\n",
    "# from sklearn.svm import SVR\n",
    "# svr = SVR(C=1.0,epsilon=0.2)\n",
    "# svr.fit(xs,ys)\n",
    "# ans_ =svr.predict(txs)\n",
    "# ans_ = np.reshape(ans_, (ans_.shape[0],1))\n",
    "# ans_ = ans_*100\n",
    "\n",
    "# # write(ans_, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 31)\n"
     ]
    }
   ],
   "source": [
    "# take = np.copy(ans_)\n",
    "# for c in [1,5,10,80,110,120]:\n",
    "#     for e in [0.1, 0.002, 0.3, 0.83, 0.99]:\n",
    "#         svr = SVR(C = c, epsilon=e)\n",
    "#         svr.fit(xs,ys)\n",
    "#         ansx = svr.predict(txs)\n",
    "#         ansx = np.reshape(ansx, (ansx.shape[0],1))\n",
    "#         ansx = ansx*100\n",
    "#         take = np.concatenate([take,ansx],axis = 1)\n",
    "        \n",
    "\n",
    "# print(take.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = np.concatenate([ans,ans_], axis = 1)\n",
    "# xx = np.max(xx, axis = 1)\n",
    "# xx\n",
    "# take = np.min(take, axis =1)\n",
    "# write(take, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write(xx, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
