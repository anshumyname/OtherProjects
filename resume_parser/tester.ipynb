{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import nltk \r\n",
    "from nltk.corpus import stopwords\r\n",
    "from numpy import dot\r\n",
    "from numpy.linalg import norm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "keywords = [\"personal\",\"projects\",\"experience\",\"skills\",\"education\"]\r\n",
    "\r\n",
    "\r\n",
    "stop_words = stopwords.words('english')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def cleanResume(resumeText):\r\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\r\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\r\n",
    "    # resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\r\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\r\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\r\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \r\n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\r\n",
    "    resumeText = [x for x in resumeText.split() if x not in stop_words]     #Removing stopwords\r\n",
    "    return resumeText"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "MAX_SEQUENCE_LENGTH = 100\r\n",
    "MAX_WORDS = None\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def read_txt (path_to_folder, dir):\r\n",
    "    indexes = []\r\n",
    "    categories = {}\r\n",
    "    for w in keywords:\r\n",
    "        categories[w] = []\r\n",
    "    for filename in dir:\r\n",
    "        file = open(path_to_folder + filename,'r')\r\n",
    "        read = file.read()\r\n",
    "        read = read.lower()\r\n",
    "        file.close()\r\n",
    "\r\n",
    "        read = cleanResume(read)\r\n",
    "\r\n",
    "        hash = {}\r\n",
    "        hash[\"personal\"] =0\r\n",
    "        for word in keywords:\r\n",
    "            if word in read:\r\n",
    "                hash[word] = read.index(word)\r\n",
    "\r\n",
    "\r\n",
    "        items = sorted(hash.items(), key = lambda x: x[1])\r\n",
    "        for i in range(len(items)):\r\n",
    "            start = items[i][1]\r\n",
    "            end = None\r\n",
    "            if (i+1)==len(items):\r\n",
    "                end = len(read)\r\n",
    "            else:\r\n",
    "                end = items[i+1][1]\r\n",
    "\r\n",
    "            categories[items[i][0]].append(read[start:end])\r\n",
    "\r\n",
    "        for w in keywords:\r\n",
    "            if w not in hash.keys():\r\n",
    "                categories[w].append('None') \r\n",
    "\r\n",
    "        indexes.append(filename)\r\n",
    "    return  categories, indexes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dir = os.listdir('./train_txt/')\r\n",
    "categories, indexes = read_txt('./train_txt/',dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = []\r\n",
    "words_dict = ['None']\r\n",
    "for i in range(len(indexes)):\r\n",
    "    row = []\r\n",
    "    for w in keywords:\r\n",
    "        row.append(categories[w][i])\r\n",
    "        if categories[w][i] is not  None:\r\n",
    "            words_dict+=categories[w][i]\r\n",
    "\r\n",
    "    data.append(row)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "df = pd.DataFrame(data, index=indexes, columns=keywords)\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal</th>\n",
       "      <th>projects</th>\n",
       "      <th>experience</th>\n",
       "      <th>skills</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>candidate_000.txt</th>\n",
       "      <td>[personal, profile, actively, seeking, opportu...</td>\n",
       "      <td>[projects, music, genre, classification, face,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[skills, python, sql, mysql, tableau, power, b...</td>\n",
       "      <td>[education, b, tech, ece, vit, ap, university,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_001.txt</th>\n",
       "      <td>[brianna, williams, junior, developer, executi...</td>\n",
       "      <td>[projects, also, contribute, knowledge, logica...</td>\n",
       "      <td>[experience, curiosity, driven, data, scientis...</td>\n",
       "      <td>[skills, towards, consistent, growth, developm...</td>\n",
       "      <td>[education, teamwork, bsc, ca, mamco, universi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_002.txt</th>\n",
       "      <td>[mason, quadrado, associate, analyst, certifie...</td>\n",
       "      <td>None</td>\n",
       "      <td>[experience, analyzing, interpreting, data, go...</td>\n",
       "      <td>[skills, python, machine, learning, mysql, dat...</td>\n",
       "      <td>[education, b, tech, b, e, electronics, teleco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_003.txt</th>\n",
       "      <td>[associate, software, engineer]</td>\n",
       "      <td>[projects, koy, ok, 1e, im, ge, tena, wal, tur...</td>\n",
       "      <td>[experience, software, engineer, machine, lear...</td>\n",
       "      <td>[skills, ava, alo, avin, zt, od, al, ms, 1, da...</td>\n",
       "      <td>[education, b, tech, v, v, 2018, activities, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_006.txt</th>\n",
       "      <td>[jennifer, armstrong, computer, vision, enthus...</td>\n",
       "      <td>[projects, understanding, images, gan, based, ...</td>\n",
       "      <td>[experience, currently, professional, experience]</td>\n",
       "      <td>[skills, machine, learning, deep, learning, co...</td>\n",
       "      <td>[education, b, tech, computer, science, iit, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_144.txt</th>\n",
       "      <td>[benjamin, osta, fresher, developer, professio...</td>\n",
       "      <td>[projects, proficient]</td>\n",
       "      <td>None</td>\n",
       "      <td>[skills, software, engineer, software, develop...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_145.txt</th>\n",
       "      <td>[jerome, pelinsky, big, data, analyst, big, da...</td>\n",
       "      <td>None</td>\n",
       "      <td>[experience, handling, kinds, data, also, used...</td>\n",
       "      <td>[skills, big, data, hadoop, hive, python, mapr...</td>\n",
       "      <td>[education, b, tech, electronics, amity, schoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_147.txt</th>\n",
       "      <td>[jaroslav, chechnik, executive, profile, work]</td>\n",
       "      <td>[projects, music, genre, classification, face,...</td>\n",
       "      <td>[experience, looking, job, opportunity, expert...</td>\n",
       "      <td>[skills, b, tech, ece, vit, ap, university, 20...</td>\n",
       "      <td>[education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_148.txt</th>\n",
       "      <td>[data, scientist]</td>\n",
       "      <td>[projects, acvaline, daal, lan, el, kx, 1e, mm...</td>\n",
       "      <td>[experience, building, deploying, end, end, an...</td>\n",
       "      <td>[skills, dy, esxoll, alot, dy, ha, wy, val, hv...</td>\n",
       "      <td>[education, b, tech, b, e, computers, rajiv, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_149.txt</th>\n",
       "      <td>[personal, profile, machine, learning, enginee...</td>\n",
       "      <td>[projects, wesbite, using, react, made, fully,...</td>\n",
       "      <td>None</td>\n",
       "      <td>[skills, artificial, intelligence, deep, learn...</td>\n",
       "      <td>[education, b, tech, hit, kancheepuram, chenna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            personal  \\\n",
       "candidate_000.txt  [personal, profile, actively, seeking, opportu...   \n",
       "candidate_001.txt  [brianna, williams, junior, developer, executi...   \n",
       "candidate_002.txt  [mason, quadrado, associate, analyst, certifie...   \n",
       "candidate_003.txt                    [associate, software, engineer]   \n",
       "candidate_006.txt  [jennifer, armstrong, computer, vision, enthus...   \n",
       "...                                                              ...   \n",
       "candidate_144.txt  [benjamin, osta, fresher, developer, professio...   \n",
       "candidate_145.txt  [jerome, pelinsky, big, data, analyst, big, da...   \n",
       "candidate_147.txt     [jaroslav, chechnik, executive, profile, work]   \n",
       "candidate_148.txt                                  [data, scientist]   \n",
       "candidate_149.txt  [personal, profile, machine, learning, enginee...   \n",
       "\n",
       "                                                            projects  \\\n",
       "candidate_000.txt  [projects, music, genre, classification, face,...   \n",
       "candidate_001.txt  [projects, also, contribute, knowledge, logica...   \n",
       "candidate_002.txt                                               None   \n",
       "candidate_003.txt  [projects, koy, ok, 1e, im, ge, tena, wal, tur...   \n",
       "candidate_006.txt  [projects, understanding, images, gan, based, ...   \n",
       "...                                                              ...   \n",
       "candidate_144.txt                             [projects, proficient]   \n",
       "candidate_145.txt                                               None   \n",
       "candidate_147.txt  [projects, music, genre, classification, face,...   \n",
       "candidate_148.txt  [projects, acvaline, daal, lan, el, kx, 1e, mm...   \n",
       "candidate_149.txt  [projects, wesbite, using, react, made, fully,...   \n",
       "\n",
       "                                                          experience  \\\n",
       "candidate_000.txt                                               None   \n",
       "candidate_001.txt  [experience, curiosity, driven, data, scientis...   \n",
       "candidate_002.txt  [experience, analyzing, interpreting, data, go...   \n",
       "candidate_003.txt  [experience, software, engineer, machine, lear...   \n",
       "candidate_006.txt  [experience, currently, professional, experience]   \n",
       "...                                                              ...   \n",
       "candidate_144.txt                                               None   \n",
       "candidate_145.txt  [experience, handling, kinds, data, also, used...   \n",
       "candidate_147.txt  [experience, looking, job, opportunity, expert...   \n",
       "candidate_148.txt  [experience, building, deploying, end, end, an...   \n",
       "candidate_149.txt                                               None   \n",
       "\n",
       "                                                              skills  \\\n",
       "candidate_000.txt  [skills, python, sql, mysql, tableau, power, b...   \n",
       "candidate_001.txt  [skills, towards, consistent, growth, developm...   \n",
       "candidate_002.txt  [skills, python, machine, learning, mysql, dat...   \n",
       "candidate_003.txt  [skills, ava, alo, avin, zt, od, al, ms, 1, da...   \n",
       "candidate_006.txt  [skills, machine, learning, deep, learning, co...   \n",
       "...                                                              ...   \n",
       "candidate_144.txt  [skills, software, engineer, software, develop...   \n",
       "candidate_145.txt  [skills, big, data, hadoop, hive, python, mapr...   \n",
       "candidate_147.txt  [skills, b, tech, ece, vit, ap, university, 20...   \n",
       "candidate_148.txt  [skills, dy, esxoll, alot, dy, ha, wy, val, hv...   \n",
       "candidate_149.txt  [skills, artificial, intelligence, deep, learn...   \n",
       "\n",
       "                                                           education  \n",
       "candidate_000.txt  [education, b, tech, ece, vit, ap, university,...  \n",
       "candidate_001.txt  [education, teamwork, bsc, ca, mamco, universi...  \n",
       "candidate_002.txt  [education, b, tech, b, e, electronics, teleco...  \n",
       "candidate_003.txt  [education, b, tech, v, v, 2018, activities, a...  \n",
       "candidate_006.txt  [education, b, tech, computer, science, iit, g...  \n",
       "...                                                              ...  \n",
       "candidate_144.txt                                               None  \n",
       "candidate_145.txt  [education, b, tech, electronics, amity, schoo...  \n",
       "candidate_147.txt                                        [education]  \n",
       "candidate_148.txt  [education, b, tech, b, e, computers, rajiv, g...  \n",
       "candidate_149.txt  [education, b, tech, hit, kancheepuram, chenna...  \n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dir = ['Job description.txt']\r\n",
    "cat, _ = read_txt('./', dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "embeddings_dict = {}\r\n",
    "embed_keys = []\r\n",
    "with open(\"glove.6B.100d.txt\", 'r', encoding=\"utf-8\") as f:\r\n",
    "    for line in f:\r\n",
    "        values = line.split()\r\n",
    "        word = values[0]\r\n",
    "        embed_keys.append(word)\r\n",
    "        vector = np.asarray(values[1:], \"float32\")\r\n",
    "        embeddings_dict[word] = vector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "jd_vec = {}\r\n",
    "unks = 0\r\n",
    "for w in keywords:\r\n",
    "    vecs = []\r\n",
    "    for word in cat[w][0]:\r\n",
    "        if word in embed_keys:\r\n",
    "            vecs.append(embeddings_dict[word])\r\n",
    "        else:\r\n",
    "            unks+=1\r\n",
    "            vecs.append(embeddings_dict['<unk>'])\r\n",
    "    vecs = np.array(vecs)\r\n",
    "    avg = np.average(vecs, axis = 0)\r\n",
    "    jd_vec[w] = avg\r\n",
    "\r\n",
    "print(\"Total unk tokens\" , unks)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total unk tokens 10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "sim_df = []\r\n",
    "unks=0\r\n",
    "all_words = []\r\n",
    "for i in range(len(indexes)):\r\n",
    "    row = []\r\n",
    "    for w in keywords:\r\n",
    "        vecs = []\r\n",
    "        for word in categories[w][i]:\r\n",
    "            all_words.append(word)\r\n",
    "            if word in embed_keys:\r\n",
    "                vecs.append(embeddings_dict[word])\r\n",
    "            else:\r\n",
    "                unks+=1\r\n",
    "                vecs.append(embeddings_dict['<unk>'])\r\n",
    "        vecs = np.array(vecs)\r\n",
    "        va = np.average(vecs, axis = 0)\r\n",
    "        cosine = None\r\n",
    "        if np.isnan(va).any():\r\n",
    "            cosine = 0\r\n",
    "        else:\r\n",
    "            vb = jd_vec[w]\r\n",
    "            cosine = dot(va,vb)/(norm(va)*norm(vb))\r\n",
    "        \r\n",
    "        row.append(cosine)\r\n",
    "    \r\n",
    "    sim_df.append(row)\r\n",
    "\r\n",
    "all_words = set(all_words)\r\n",
    "print(\"Total words extracted are \", len(all_words))\r\n",
    "print(\"Total unk tokens\" , unks)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total words extracted are  2319\n",
      "Total unk tokens 450\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Similartiy Table\r\n",
    "similariy = pd.DataFrame(sim_df, index=indexes, columns=keywords)\r\n",
    "similariy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personal</th>\n",
       "      <th>projects</th>\n",
       "      <th>experience</th>\n",
       "      <th>skills</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>candidate_000.txt</th>\n",
       "      <td>0.888378</td>\n",
       "      <td>0.295928</td>\n",
       "      <td>0.415252</td>\n",
       "      <td>0.636419</td>\n",
       "      <td>0.856955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_001.txt</th>\n",
       "      <td>0.610979</td>\n",
       "      <td>0.234160</td>\n",
       "      <td>0.776972</td>\n",
       "      <td>0.762761</td>\n",
       "      <td>0.882273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_002.txt</th>\n",
       "      <td>0.668103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620666</td>\n",
       "      <td>0.924627</td>\n",
       "      <td>0.754305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_003.txt</th>\n",
       "      <td>0.694706</td>\n",
       "      <td>0.378404</td>\n",
       "      <td>0.694232</td>\n",
       "      <td>0.825477</td>\n",
       "      <td>0.770898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_006.txt</th>\n",
       "      <td>0.906714</td>\n",
       "      <td>0.300554</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.881404</td>\n",
       "      <td>0.773082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_144.txt</th>\n",
       "      <td>0.900714</td>\n",
       "      <td>0.164987</td>\n",
       "      <td>0.415252</td>\n",
       "      <td>0.853482</td>\n",
       "      <td>0.393262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_145.txt</th>\n",
       "      <td>0.738020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758193</td>\n",
       "      <td>0.920389</td>\n",
       "      <td>0.725882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_147.txt</th>\n",
       "      <td>0.576090</td>\n",
       "      <td>0.273347</td>\n",
       "      <td>0.758924</td>\n",
       "      <td>0.730275</td>\n",
       "      <td>0.708900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_148.txt</th>\n",
       "      <td>0.698836</td>\n",
       "      <td>0.395247</td>\n",
       "      <td>0.733054</td>\n",
       "      <td>0.694591</td>\n",
       "      <td>0.529111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_149.txt</th>\n",
       "      <td>0.872008</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>0.415252</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.740257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   personal  projects  experience    skills  education\n",
       "candidate_000.txt  0.888378  0.295928    0.415252  0.636419   0.856955\n",
       "candidate_001.txt  0.610979  0.234160    0.776972  0.762761   0.882273\n",
       "candidate_002.txt  0.668103  1.000000    0.620666  0.924627   0.754305\n",
       "candidate_003.txt  0.694706  0.378404    0.694232  0.825477   0.770898\n",
       "candidate_006.txt  0.906714  0.300554    0.769333  0.881404   0.773082\n",
       "...                     ...       ...         ...       ...        ...\n",
       "candidate_144.txt  0.900714  0.164987    0.415252  0.853482   0.393262\n",
       "candidate_145.txt  0.738020  1.000000    0.758193  0.920389   0.725882\n",
       "candidate_147.txt  0.576090  0.273347    0.758924  0.730275   0.708900\n",
       "candidate_148.txt  0.698836  0.395247    0.733054  0.694591   0.529111\n",
       "candidate_149.txt  0.872008  0.358750    0.415252  0.663939   0.740257\n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "similariy.fillna(0, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "xs = np.array(similariy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "target = pd.read_csv('./dataset/train.csv', index_col='CandidateID')\r\n",
    "target.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CandidateID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>candidate_011</th>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_113</th>\n",
       "      <td>36.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_123</th>\n",
       "      <td>54.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_012</th>\n",
       "      <td>41.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate_002</th>\n",
       "      <td>48.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Match Percentage\n",
       "CandidateID                    \n",
       "candidate_011             13.60\n",
       "candidate_113             36.63\n",
       "candidate_123             54.93\n",
       "candidate_012             41.46\n",
       "candidate_002             48.91"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "ys = []\r\n",
    "for i in indexes:\r\n",
    "    ys.append(target.loc[i[:-4]]['Match Percentage']/100)\r\n",
    "ys = np.array(ys, dtype = np.float32)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "xs = xs.astype(np.float32)\r\n",
    "ys = ys.astype(np.float32)\r\n",
    "print(xs.shape)\r\n",
    "print(ys.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(90, 5)\n",
      "(90,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size = 0.1, random_state = 42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from keras.models import Sequential, Model\r\n",
    "from keras.layers import Dense , Dropout, Activation\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def build_model():\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_shape =[5,]))\r\n",
    "    model.add(Dense(8))\r\n",
    "    model.add(Dense(1))\r\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics =['mse'])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model = build_model()\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "history = model.fit(X_train,y_train, epochs=100,validation_data=(X_test,y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 3s 146ms/step - loss: 0.8432 - mse: 0.8432 - val_loss: 0.7007 - val_mse: 0.7007\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.5713 - mse: 0.5713 - val_loss: 0.5889 - val_mse: 0.5889\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.4523 - mse: 0.4523 - val_loss: 0.5309 - val_mse: 0.5309\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3858 - mse: 0.3858 - val_loss: 0.4918 - val_mse: 0.4918\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3401 - mse: 0.3401 - val_loss: 0.4664 - val_mse: 0.4664\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3108 - mse: 0.3108 - val_loss: 0.4479 - val_mse: 0.4479\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.2898 - mse: 0.2898 - val_loss: 0.4330 - val_mse: 0.4330\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.2775 - mse: 0.2775 - val_loss: 0.4166 - val_mse: 0.4166\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2616 - mse: 0.2616 - val_loss: 0.4046 - val_mse: 0.4046\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2484 - mse: 0.2484 - val_loss: 0.3900 - val_mse: 0.3900\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2377 - mse: 0.2377 - val_loss: 0.3813 - val_mse: 0.3813\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2269 - mse: 0.2269 - val_loss: 0.3705 - val_mse: 0.3705\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.3512 - val_mse: 0.3512\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2079 - mse: 0.2079 - val_loss: 0.3393 - val_mse: 0.3393\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1986 - mse: 0.1986 - val_loss: 0.3259 - val_mse: 0.3259\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1910 - mse: 0.1910 - val_loss: 0.3135 - val_mse: 0.3135\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1802 - mse: 0.1802 - val_loss: 0.3005 - val_mse: 0.3005\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1718 - mse: 0.1718 - val_loss: 0.2883 - val_mse: 0.2883\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1633 - mse: 0.1633 - val_loss: 0.2768 - val_mse: 0.2768\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1559 - mse: 0.1559 - val_loss: 0.2642 - val_mse: 0.2642\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1460 - mse: 0.1460 - val_loss: 0.2537 - val_mse: 0.2537\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1380 - mse: 0.1380 - val_loss: 0.2459 - val_mse: 0.2459\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1325 - mse: 0.1325 - val_loss: 0.2336 - val_mse: 0.2336\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1236 - mse: 0.1236 - val_loss: 0.2270 - val_mse: 0.2270\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 0.2177 - val_mse: 0.2177\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1100 - mse: 0.1100 - val_loss: 0.2059 - val_mse: 0.2059\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1050 - mse: 0.1050 - val_loss: 0.2057 - val_mse: 0.2057\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 0.1830 - val_mse: 0.1830\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.1747 - val_mse: 0.1747\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0869 - mse: 0.0869 - val_loss: 0.1743 - val_mse: 0.1743\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0822 - mse: 0.0822 - val_loss: 0.1567 - val_mse: 0.1567\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0770 - mse: 0.0770 - val_loss: 0.1488 - val_mse: 0.1488\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.1454 - val_mse: 0.1454\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0674 - mse: 0.0674 - val_loss: 0.1390 - val_mse: 0.1390\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0638 - mse: 0.0638 - val_loss: 0.1247 - val_mse: 0.1247\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.1248 - val_mse: 0.1248\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0556 - mse: 0.0556 - val_loss: 0.1185 - val_mse: 0.1185\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.1122 - val_mse: 0.1122\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0492 - mse: 0.0492 - val_loss: 0.1035 - val_mse: 0.1035\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.1002 - val_mse: 0.1002\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.1014 - val_mse: 0.1014\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.1076 - val_mse: 0.1076\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0362 - mse: 0.0362 - val_loss: 0.0893 - val_mse: 0.0893\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0838 - val_mse: 0.0838\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0767 - val_mse: 0.0767\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0748 - val_mse: 0.0748\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0703 - val_mse: 0.0703\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0588 - val_mse: 0.0588\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0564 - val_mse: 0.0564\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0615 - val_mse: 0.0615\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0547 - val_mse: 0.0547\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0461 - val_mse: 0.0461\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0517 - val_mse: 0.0517\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0479 - val_mse: 0.0479\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0521 - val_mse: 0.0521\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0446 - val_mse: 0.0446\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0406 - val_mse: 0.0406\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0482 - val_mse: 0.0482\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0423 - val_mse: 0.0423\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0448 - val_mse: 0.0448\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0430 - val_mse: 0.0430\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0483 - val_mse: 0.0483\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0487 - val_mse: 0.0487\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0476 - val_mse: 0.0476\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0548 - val_mse: 0.0548\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0556 - val_mse: 0.0556\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0426 - val_mse: 0.0426\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0459 - val_mse: 0.0459\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0468 - val_mse: 0.0468\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "plt.plot(history.history['mse'])\r\n",
    "plt.plot(history.history['val_mse'])\r\n",
    "plt.title('model accuracy')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.xlabel('epoch')\r\n",
    "plt.legend(['train', 'test'], loc='upper left')\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#Testing\r\n",
    "dir = os.listdir('./test_txt/')\r\n",
    "test_cat, test_index = read_txt('./test_txt/',dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "test_df = []\r\n",
    "for i in range(len(test_index)):\r\n",
    "    row = []\r\n",
    "    for w in keywords:\r\n",
    "        vecs = []\r\n",
    "        for word in test_cat[w][i]:\r\n",
    "            if word in embed_keys:\r\n",
    "                vecs.append(embeddings_dict[word])\r\n",
    "            else:\r\n",
    "                vecs.append(embeddings_dict['<unk>'])\r\n",
    "        vecs = np.array(vecs)\r\n",
    "        va = np.average(vecs, axis = 0)\r\n",
    "        cosine = None\r\n",
    "        if np.isnan(va).any():\r\n",
    "            cosine = 0\r\n",
    "        else:\r\n",
    "            vb = jd_vec[w]\r\n",
    "            cosine = dot(va,vb)/(norm(va)*norm(vb))\r\n",
    "        \r\n",
    "        row.append(cosine)\r\n",
    "    \r\n",
    "    test_df.append(row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\sriva\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "test_sim = pd.DataFrame(test_df, index=test_index, columns=keywords)\r\n",
    "test_sim.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 60 entries, candidate_004.txt to candidate_146.txt\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   personal    60 non-null     float64\n",
      " 1   projects    60 non-null     float32\n",
      " 2   experience  60 non-null     float32\n",
      " 3   skills      60 non-null     float32\n",
      " 4   education   60 non-null     float32\n",
      "dtypes: float32(4), float64(1)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "txs = np.array(test_sim)\r\n",
    "print(txs.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 5)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "ans = model.predict(txs)\r\n",
    "ans = np.reshape(ans, (ans.shape[0],1))\r\n",
    "ans = ans*100 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def write(ans,test_index):\r\n",
    "    ans = np.reshape(ans, (ans.shape[0],1))\r\n",
    "    ans_index = np.array([x[:-4] for x in test_index])\r\n",
    "    ans_index = np.reshape(np.ravel(ans_index) , ans.shape)\r\n",
    "    ans = np.concatenate([ans_index,ans] , axis = 1)\r\n",
    "    ans_df = pd.DataFrame(ans, index=None, columns=['CandidateID','Match Percentage'])\r\n",
    "    print(\"Written new file\")\r\n",
    "    ans_df.to_csv('submission.csv',index=None)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "## Trying other models\r\n",
    "from sklearn.svm import SVR\r\n",
    "svr = SVR(C=1.0,epsilon=0.2)\r\n",
    "svr.fit(xs,ys)\r\n",
    "ans_ =svr.predict(txs)\r\n",
    "ans_ = np.reshape(ans_, (ans_.shape[0],1))\r\n",
    "ans_ = ans_*100\r\n",
    "\r\n",
    "# write(ans_, test_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "take = np.copy(ans_)\r\n",
    "for c in [1,5,10,80,110,120]:\r\n",
    "    for e in [0.1, 0.002, 0.3, 0.83, 0.99]:\r\n",
    "        svr = SVR(C = c, epsilon=e)\r\n",
    "        svr.fit(xs,ys)\r\n",
    "        ansx = svr.predict(txs)\r\n",
    "        ansx = np.reshape(ansx, (ansx.shape[0],1))\r\n",
    "        ansx = ansx*100\r\n",
    "        take = np.concatenate([take,ansx],axis = 1)\r\n",
    "        \r\n",
    "\r\n",
    "print(take.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60, 31)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# xx = np.concatenate([ans,ans_], axis = 1)\r\n",
    "# xx = np.max(xx, axis = 1)\r\n",
    "# xx\r\n",
    "take = np.min(take, axis =1)\r\n",
    "write(take, test_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# write(xx, test_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "sim_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0.8883778, 0.29592833, 0.415252, 0.6364191, 0.8569552],\n",
       " [0.61097926, 0.23415965, 0.77697176, 0.7627605, 0.88227266],\n",
       " [0.66810286, 1.0, 0.62066585, 0.92462736, 0.75430495],\n",
       " [0.6947064, 0.37840423, 0.6942319, 0.8254774, 0.7708976],\n",
       " [0.9067139, 0.3005535, 0.76933324, 0.8814044, 0.77308196],\n",
       " [0.8622184, 0.26828837, 0.5923649, 0.8857072, 0.8472573],\n",
       " [0.7662991, 0.29844406, 0.71198624, 0.89622736, 0.8148804],\n",
       " [0.87884367, 1.0, 0.7653649, 0.9167172, 0.70842457],\n",
       " [0.8062151, 0.37531516, 0.7211594, 0.62105846, 0.8475659],\n",
       " [0.89601, 1.0, 0.7691308, 0.49025878, 0.39326173],\n",
       " [0.8031282, 0.39070997, 0.415252, 0.9175321, 0.39326173],\n",
       " [0.65824354, 0.28509477, 0.71453303, 0.80462074, 0.76407284],\n",
       " [0.8402332, 0.20913859, 0.7447718, 0.841462, 0.75217324],\n",
       " [0.66937876, 0.32378915, 0.7058372, 0.8362547, 0.8839337],\n",
       " [0.9144753, 0.27800855, 0.78372127, 0.9103799, 0.7644413],\n",
       " [0.8660931, 0.38663623, 0.6984991, 0.9099471, 0.70065427],\n",
       " [0.86044085, 1.0, 0.73467994, 0.49025878, 0.39326173],\n",
       " [0.6806485, 0.29538748, 0.72818077, 0.749548, 0.6854135],\n",
       " [0.9140072, 0.27477443, 0.415252, 0.9182949, 0.39326173],\n",
       " [0.851659, 0.24861316, 0.415252, 0.93092614, 0.86394864],\n",
       " [0.75155514, 0.2873466, 0.7058372, 0.90734726, 0.8878072],\n",
       " [0.6037494, 0.35527787, 0.76822895, 0.49025878, 0.39326173],\n",
       " [0.7138633, 0.24816963, 0.7846928, 0.92040193, 0.39326173],\n",
       " [0.8890592, 0.25686887, 0.74764687, 0.85102457, 0.85443014],\n",
       " [0.92772603, 1.0, 0.7942088, 0.49025878, 0.39326173],\n",
       " [0.07408005, 0.50618666, 0.47461602, 0.8691955, 0.80362475],\n",
       " [0.84089243, 1.0, 0.7637397, 0.9179034, 0.68025076],\n",
       " [0.8149218, 0.36835688, 0.7058372, 0.9130491, 0.81687886],\n",
       " [0.86224735, 0.31517112, 0.415252, 0.86995476, 0.39326173],\n",
       " [0.8877769, 0.33521512, 0.415252, 0.23967943, 0.7717984],\n",
       " [0.80458295, 0.31494084, 0.7099685, 0.89112735, 0.7092982],\n",
       " [0.91874766, 0.30628473, 0.8179988, 0.821967, 0.7449819],\n",
       " [0.6988357, 0.36837748, 0.7906754, 0.7769171, 0.7877612],\n",
       " [0.88200486, 1.0, 0.7882117, 0.9305172, 0.8185422],\n",
       " [0.50783354, 0.042943645, 0.7058372, 0.9001447, 0.8338341],\n",
       " [0.86946154, 0.33080402, 0.415252, 0.9169496, 0.39326173],\n",
       " [0.87572366, 0.2659745, 0.415252, 0.8954288, 0.7849054],\n",
       " [0.9080947, 0.26223147, 0.7698096, 0.9115295, 0.7644107],\n",
       " [0.9141654, 0.37733245, 0.4937187, 0.8574474, 0.6142596],\n",
       " [0.89453566, 0.2799582, 0.7265019, 0.9184636, 0.83008385],\n",
       " [0.90686554, 1.0, 0.75350356, 0.49025878, 0.39326173],\n",
       " [0.64463484, 0.33525267, 0.6887802, 0.83380103, 0.8527586],\n",
       " [0.7000755, 0.26496503, 0.7539118, 0.92999655, 0.39326173],\n",
       " [0.9241676, 1.0, 0.70972043, 0.9306324, 0.66539556],\n",
       " [0.61516684, 0.26481506, 0.7048936, 0.90172195, 0.7027919],\n",
       " [0, 1.0, 0.7621391, 0.49025878, 0.39326173],\n",
       " [0.8361417, 0.29593673, 0.415252, 0.9376426, 0.39326173],\n",
       " [0.60555094, 0.29398492, 0.7863865, 0.8043748, 0.86535287],\n",
       " [0.6012666, 0.34641492, 0.7279129, 0.49025878, 0.39326173],\n",
       " [0.8150575, 0.38822174, 0.61265624, 0.8932668, 0.7846185],\n",
       " [0.89206004, 1.0, 0.415252, 0.9420183, 0.39326173],\n",
       " [0.8990634, 0.34883025, 0.415252, 0.9260866, 0.85236686],\n",
       " [0.83679104, 1.0, 0.7220366, 0.90915656, 0.63083595],\n",
       " [0.86297923, 1.0, 0.7800586, 0.49025878, 0.39326173],\n",
       " [0.51913893, 0.27727658, 0.7345118, 0.75372136, 0.7901036],\n",
       " [0.8598415, 0.33519113, 0.415252, 0.86529744, 0.39326173],\n",
       " [0.84396225, 0.30953673, 0.415252, 0.5807965, 0.8522429],\n",
       " [0.74724144, 1.0, 0.74932945, 0.49025878, 0.39326173],\n",
       " [0.5928996, 0.21702258, 0.7058372, 0.87844694, 0.8965025],\n",
       " [0.52936476, 0.27735066, 0.7476368, 0.87224966, 0.666852],\n",
       " [0.82228464, 1.0, 0.79225457, 0.49025878, 0.39326173],\n",
       " [0.44802037, 0.46249944, 0.70511115, 0.60425556, 0.8068432],\n",
       " [0.7845682, 1.0, 0.7071199, 0.9214914, 0.6576],\n",
       " [0.8804539, 0.30931175, 0.415252, 0.5807965, 0.79809946],\n",
       " [0.6321628, 1.0, 0.76112396, 0.74205244, 0.8561645],\n",
       " [0.8132636, 0.33136225, 0.415252, 0.920729, 0.39326173],\n",
       " [0.59895104, 0.26693934, 0.7058372, 0.91401654, 0.86149406],\n",
       " [0.87016326, 0.12771773, 0.415252, 0.5807965, 0.82068694],\n",
       " [0.76335096, 0.2587781, 0.7371391, 0.90332425, 0.7173452],\n",
       " [0.8876738, 0.29899377, 0.7000879, 0.90571696, 0.39326173],\n",
       " [0.81919676, 0.110601075, 0.7323612, 0.92245436, 0.52492064],\n",
       " [0.41045368, 1.0, 0.7998078, 0.49025878, 0.39326173],\n",
       " [0.8902394, 0.16819529, 0.7155042, 0.89298695, 0.6150706],\n",
       " [0.9001753, 0.38060227, 0.7058372, 0.8889802, 0.7973189],\n",
       " [0.81141347, 0.40265733, 0.72157246, 0.91812426, 0.7373161],\n",
       " [0.8780563, 0.33761707, 0.415252, 0.90387475, 0.39326173],\n",
       " [0.85389733, 0.16819529, 0.63656825, 0.8690537, 0.38221613],\n",
       " [0.8367947, 0.3161519, 0.757676, 0.91904867, 0.8085589],\n",
       " [0.46581298, 0.27211806, 0.73479867, 0.89472497, 0.8300557],\n",
       " [0.9120666, 1.0, 0.7713398, 0.9306131, 0.39326173],\n",
       " [0.8906481, 0.3069953, 0.415252, 0.8359937, 0.39326173],\n",
       " [0.89172655, 0.16819529, 0.76705754, 0.93271685, 0.7362548],\n",
       " [0.828003, 0.23758444, 0.7380192, 0.8730717, 0.7144943],\n",
       " [0.9015574, 0.30834377, 0.66055554, 0.88942975, 0.777964],\n",
       " [0.8139108, 1.0, 0.772103, 0.8956433, 0.39326173],\n",
       " [0.9007141, 0.16498697, 0.415252, 0.8534825, 0.39326173],\n",
       " [0.7380196, 1.0, 0.7581928, 0.9203885, 0.7258822],\n",
       " [0.57609004, 0.27334747, 0.7589241, 0.7302753, 0.7088998],\n",
       " [0.6988357, 0.3952465, 0.733054, 0.6945912, 0.52911055],\n",
       " [0.8720084, 0.3587501, 0.415252, 0.6639387, 0.7402569]]"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "from sklearn.linear_model import Ridge\r\n",
    "ridge = Ridge()\r\n",
    "ridge.fit(xs,ys)\r\n",
    "ansr = ridge.predict(txs)\r\n",
    "ansr = ansr*100\r\n",
    "write(ansr, test_index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Written new file\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}